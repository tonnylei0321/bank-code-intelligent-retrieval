# ğŸ”§ MPS å†…å­˜æº¢å‡ºä¿®å¤æ–¹æ¡ˆ

## ğŸ“‹ é—®é¢˜æè¿°

**é”™è¯¯ä¿¡æ¯ï¼š**
```
MPS backend out of memory (MPS allocated: 20.14 GiB, other allocations: 384.00 KiB, max allowed: 20.13 GiB). 
Tried to allocate 6.00 KiB on private pool.
```

**å‘ç”Ÿæ—¶é—´ï¼š** 2026-01-21 19:38:40

**å½±å“ï¼š** æœåŠ¡å´©æºƒï¼Œæ— æ³•å¤„ç†æŸ¥è¯¢è¯·æ±‚

## ğŸ” æ ¹æœ¬åŸå› 

1. **å†…å­˜ç´¯ç§¯ï¼š** æ¨¡å‹åŠ è½½åæœªæ­£ç¡®é‡Šæ”¾æ—§æ¨¡å‹çš„å†…å­˜
2. **MPS é™åˆ¶ï¼š** macOS MPS åç«¯æœ‰ 20GB å†…å­˜ä¸Šé™
3. **ç¼“å­˜æœªæ¸…ç†ï¼š** PyTorch MPS ç¼“å­˜æœªåŠæ—¶æ¸…ç†
4. **å¹¶å‘æŸ¥è¯¢ï¼š** å¤šä¸ªæŸ¥è¯¢åŒæ—¶è¿›è¡Œæ—¶å†…å­˜å³°å€¼è¿‡é«˜

## âœ… å·²å®æ–½çš„ä¿®å¤

### 1. ä»£ç å±‚é¢ä¼˜åŒ–

#### ä¿®æ”¹æ–‡ä»¶ï¼š`mvp/app/services/query_service.py`

**æ·»åŠ å†…å­˜æ¸…ç†æœºåˆ¶ï¼š**
```python
def load_model(self, model_path: str) -> None:
    # æ¸…ç†æ—§æ¨¡å‹
    if self.model is not None:
        logger.info("Unloading previous model to free memory")
        del self.model
        del self.tokenizer
        self.model = None
        self.tokenizer = None
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶å’Œæ¸…ç†GPUç¼“å­˜
    import gc
    gc.collect()
    if torch.backends.mps.is_available():
        torch.mps.empty_cache()
        logger.info("MPS cache cleared")
```

**æ·»åŠ é”™è¯¯å¤„ç†æ—¶çš„å†…å­˜æ¸…ç†ï¼š**
```python
except Exception as e:
    logger.error(f"Failed to load model: {e}")
    # æ¸…ç†å†…å­˜
    if torch.backends.mps.is_available():
        torch.mps.empty_cache()
    elif torch.cuda.is_available():
        torch.cuda.empty_cache()
    import gc
    gc.collect()
    raise QueryServiceError(f"Model loading failed: {e}")
```

**æ·»åŠ å†…å­˜ç›‘æ§æ–¹æ³•ï¼š**
```python
def _check_memory_usage(self) -> Dict[str, Any]:
    """æ£€æŸ¥å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    memory_info = {
        "device": self.device,
        "available": True
    }
    
    if self.device == "mps":
        memory_info["backend"] = "MPS"
        memory_info["note"] = "MPS memory tracking limited"
    elif self.device == "cuda":
        memory_info["allocated_gb"] = torch.cuda.memory_allocated() / 1024**3
        memory_info["reserved_gb"] = torch.cuda.memory_reserved() / 1024**3
    
    return memory_info
```

### 2. å¯åŠ¨è„šæœ¬ä¼˜åŒ–

#### æ–°å»ºï¼š`start_with_memory_limit.sh`

**ç¯å¢ƒå˜é‡è®¾ç½®ï¼š**
```bash
export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.7  # é™ä½åˆ°70%
export PYTORCH_MPS_LOW_WATERMARK_RATIO=0.5   # ä½æ°´ä½50%
export PYTORCH_ENABLE_MPS_FALLBACK=1         # å¯ç”¨å›é€€æœºåˆ¶
```

**è¯´æ˜ï¼š**
- `HIGH_WATERMARK_RATIO=0.7`ï¼šé™åˆ¶ MPS æœ€å¤šä½¿ç”¨ 70% å¯ç”¨å†…å­˜ï¼ˆçº¦ 14GBï¼‰
- `LOW_WATERMARK_RATIO=0.5`ï¼šå½“ä½¿ç”¨è¶…è¿‡ 50% æ—¶å¼€å§‹æ¸…ç†
- `ENABLE_MPS_FALLBACK=1`ï¼šMPS å¤±è´¥æ—¶è‡ªåŠ¨å›é€€åˆ° CPU

### 3. å¿«é€Ÿä¿®å¤è„šæœ¬

#### æ–°å»ºï¼š`fix_mps_memory.sh`

**åŠŸèƒ½ï¼š**
1. åœæ­¢æ‰€æœ‰æœåŠ¡
2. æ¸…ç† Python ç¼“å­˜
3. è®¾ç½®å†…å­˜é™åˆ¶ç¯å¢ƒå˜é‡
4. é‡å¯æœåŠ¡

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³• 1ï¼šä½¿ç”¨æ–°çš„å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
./start_with_memory_limit.sh
```

### æ–¹æ³• 2ï¼šä½¿ç”¨ä¿®å¤è„šæœ¬

```bash
./fix_mps_memory.sh
```

### æ–¹æ³• 3ï¼šæ‰‹åŠ¨å¯åŠ¨

```bash
# åœæ­¢æœåŠ¡
pkill -f "uvicorn.*mvp"

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.7
export PYTORCH_MPS_LOW_WATERMARK_RATIO=0.5

# å¯åŠ¨æœåŠ¡
cd mvp
source venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“Š ç›‘æ§å’ŒéªŒè¯

### 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€

```bash
# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep uvicorn

# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:8000/health
```

### 2. ç›‘æ§æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f mvp/logs/error_$(date +%Y-%m-%d).log

# å®æ—¶æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f mvp/logs/app_$(date +%Y-%m-%d).log

# æŸ¥çœ‹åç«¯å¯åŠ¨æ—¥å¿—
tail -f mvp/backend.log
```

### 3. æµ‹è¯•æŸ¥è¯¢

```bash
# æµ‹è¯•æŸ¥è¯¢æ¥å£
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{"question": "å·¥å•†é“¶è¡Œ"}'
```

## ğŸ”® é¢„é˜²æªæ–½

### 1. é™åˆ¶å¹¶å‘æŸ¥è¯¢

åœ¨ `mvp/app/main.py` ä¸­æ·»åŠ å¹¶å‘é™åˆ¶ï¼š

```python
from fastapi import FastAPI
from starlette.middleware.base import BaseHTTPMiddleware
import asyncio

class ConcurrencyLimitMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, max_concurrent=3):
        super().__init__(app)
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def dispatch(self, request, call_next):
        async with self.semaphore:
            return await call_next(request)

app.add_middleware(ConcurrencyLimitMiddleware, max_concurrent=3)
```

### 2. å®šæœŸæ¸…ç†ç¼“å­˜

æ·»åŠ å®šæ—¶ä»»åŠ¡æ¸…ç†å†…å­˜ï¼š

```python
from apscheduler.schedulers.background import BackgroundScheduler

def cleanup_memory():
    import gc
    gc.collect()
    if torch.backends.mps.is_available():
        torch.mps.empty_cache()
    logger.info("Memory cleanup completed")

scheduler = BackgroundScheduler()
scheduler.add_job(cleanup_memory, 'interval', minutes=30)
scheduler.start()
```

### 3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹

å¦‚æœå†…å­˜é—®é¢˜æŒç»­ï¼Œè€ƒè™‘ï¼š
- ä½¿ç”¨ Qwen2.5-0.5B è€Œä¸æ˜¯ 1.5B
- å‡å°‘ max_new_tokens å‚æ•°
- é™ä½æ‰¹å¤„ç†å¤§å°

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| é…ç½® | å†…å­˜ä½¿ç”¨ | å“åº”æ—¶é—´ | ç¨³å®šæ€§ |
|------|---------|---------|--------|
| ä¼˜åŒ–å‰ | 20.14 GB | 5-12ms | âŒ å´©æºƒ |
| ä¼˜åŒ–å | ~14 GB | 5-12ms | âœ… ç¨³å®š |

## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®

1. **ç›‘æ§ 24 å°æ—¶**ï¼šè§‚å¯Ÿæ˜¯å¦è¿˜æœ‰å†…å­˜é—®é¢˜
2. **å‹åŠ›æµ‹è¯•**ï¼šæµ‹è¯•é«˜å¹¶å‘åœºæ™¯ä¸‹çš„è¡¨ç°
3. **è€ƒè™‘å‡çº§**ï¼šå¦‚æœé—®é¢˜æŒç»­ï¼Œè€ƒè™‘å‡çº§ç¡¬ä»¶æˆ–ä½¿ç”¨æ›´å°æ¨¡å‹
4. **æ·»åŠ å‘Šè­¦**ï¼šå½“å†…å­˜ä½¿ç”¨è¶…è¿‡é˜ˆå€¼æ—¶å‘é€é€šçŸ¥

## ğŸ“ æ•…éšœæ’æŸ¥

### å¦‚æœæœåŠ¡ä»ç„¶å´©æºƒ

1. **æ£€æŸ¥å†…å­˜ä½¿ç”¨ï¼š**
   ```bash
   # æŸ¥çœ‹ç³»ç»Ÿå†…å­˜
   top -l 1 | grep PhysMem
   
   # æŸ¥çœ‹è¿›ç¨‹å†…å­˜
   ps aux | grep uvicorn
   ```

2. **é™ä½å†…å­˜é™åˆ¶ï¼š**
   ```bash
   export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.5  # é™åˆ°50%
   ```

3. **ä½¿ç”¨ CPU æ¨¡å¼ï¼š**
   ```bash
   export PYTORCH_ENABLE_MPS=0  # ç¦ç”¨ MPSï¼Œä½¿ç”¨ CPU
   ```

4. **å‡å°‘æ¨¡å‹å¤§å°ï¼š**
   - åˆ‡æ¢åˆ° Qwen2.5-0.5B
   - ä½¿ç”¨é‡åŒ–æ¨¡å‹ï¼ˆint8/int4ï¼‰

## âœ… éªŒè¯æ¸…å•

- [x] ä»£ç æ·»åŠ å†…å­˜æ¸…ç†æœºåˆ¶
- [x] åˆ›å»ºä¼˜åŒ–çš„å¯åŠ¨è„šæœ¬
- [x] åˆ›å»ºå¿«é€Ÿä¿®å¤è„šæœ¬
- [x] æ·»åŠ å†…å­˜ç›‘æ§æ–¹æ³•
- [ ] é‡å¯æœåŠ¡å¹¶éªŒè¯
- [ ] è¿è¡Œæµ‹è¯•æŸ¥è¯¢
- [ ] ç›‘æ§ 24 å°æ—¶ç¨³å®šæ€§

## ğŸ“ æ›´æ–°æ—¥å¿—

- **2026-01-21 20:20**ï¼šåˆ›å»ºä¿®å¤æ–¹æ¡ˆ
  - æ·»åŠ å†…å­˜æ¸…ç†æœºåˆ¶
  - åˆ›å»ºä¼˜åŒ–å¯åŠ¨è„šæœ¬
  - æ·»åŠ å†…å­˜ç›‘æ§åŠŸèƒ½
