#!/usr/bin/env python3
"""
è®­ç»ƒä»»åŠ¡å†…å­˜ä¼˜åŒ–å¯åŠ¨è„šæœ¬
ä¸“é—¨è§£å†³MPSå†…å­˜æº¢å‡ºé—®é¢˜çš„è®­ç»ƒå¯åŠ¨å™¨
"""

import os
import sys
import sqlite3
import subprocess
import time
import json
from datetime import datetime
from pathlib import Path

def setup_memory_environment():
    """è®¾ç½®å†…å­˜ä¼˜åŒ–ç¯å¢ƒå˜é‡"""
    print("ğŸ”§ é…ç½®å†…å­˜ä¼˜åŒ–ç¯å¢ƒ...")
    
    # æ›´æ¿€è¿›çš„å†…å­˜é™åˆ¶
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.5'  # é™åˆ°50%
    os.environ['PYTORCH_MPS_LOW_WATERMARK_RATIO'] = '0.3'   # é™åˆ°30%
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    os.environ['PYTORCH_MPS_ALLOCATOR_POLICY'] = 'garbage_collection'
    
    # é™åˆ¶OMPçº¿ç¨‹æ•°ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
    os.environ['OMP_NUM_THREADS'] = '2'
    os.environ['MKL_NUM_THREADS'] = '2'
    
    print("âœ… å†…å­˜ç¯å¢ƒé…ç½®å®Œæˆ")
    print(f"   MPSé«˜æ°´ä½: {os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO']}")
    print(f"   MPSä½æ°´ä½: {os.environ['PYTORCH_MPS_LOW_WATERMARK_RATIO']}")

def clear_memory():
    """æ¸…ç†ç³»ç»Ÿå†…å­˜"""
    print("ğŸ§¹ æ¸…ç†ç³»ç»Ÿå†…å­˜...")
    
    # åœæ­¢å¯èƒ½å ç”¨å†…å­˜çš„è¿›ç¨‹
    subprocess.run(['pkill', '-f', 'python.*training'], capture_output=True)
    time.sleep(2)
    
    # æ¸…ç†Pythonç¼“å­˜
    subprocess.run(['find', '.', '-type', 'd', '-name', '__pycache__', '-exec', 'rm', '-rf', '{}', '+'], 
                  capture_output=True, cwd='mvp')
    
    print("âœ… å†…å­˜æ¸…ç†å®Œæˆ")

def create_small_training_dataset():
    """åˆ›å»ºæ›´å°çš„è®­ç»ƒæ•°æ®é›† - 5ä¸‡æ ·æœ¬"""
    print("ğŸ“Š åˆ›å»ºå°å‹è®­ç»ƒæ•°æ®é›†...")
    
    try:
        conn = sqlite3.connect('mvp/data/bank_code.db')
        cursor = conn.cursor()
        
        # æ£€æŸ¥æœ€æ–°æ•°æ®é›†
        cursor.execute("SELECT id, sample_count FROM datasets ORDER BY created_at DESC LIMIT 1")
        latest_dataset = cursor.fetchone()
        
        if not latest_dataset:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®é›†")
            return None
            
        latest_id, total_samples = latest_dataset
        print(f"ğŸ“‹ æœ€æ–°æ•°æ®é›†: {latest_id}, æ€»æ ·æœ¬: {total_samples}")
        
        # åˆ›å»º5ä¸‡æ ·æœ¬çš„å°æ•°æ®é›†
        target_samples = 50000
        
        # éšæœºæŠ½å–5ä¸‡æ ·æœ¬
        cursor.execute(f"""
            INSERT INTO datasets (name, description, sample_count, created_at)
            VALUES ('å°å‹è®­ç»ƒé›†-5ä¸‡æ ·æœ¬', 'ä»æ•°æ®é›†{latest_id}ä¸­éšæœºæŠ½å–5ä¸‡æ ·æœ¬ç”¨äºå†…å­˜ä¼˜åŒ–è®­ç»ƒ', {target_samples}, ?)
        """, (datetime.now().isoformat(),))
        
        new_dataset_id = cursor.lastrowid
        
        # å¤åˆ¶æ ·æœ¬æ•°æ®
        cursor.execute(f"""
            INSERT INTO qa_pairs (dataset_id, question, answer, question_type, bank_name, bank_code, created_at)
            SELECT {new_dataset_id}, question, answer, question_type, bank_name, bank_code, ?
            FROM qa_pairs 
            WHERE dataset_id = {latest_id}
            ORDER BY RANDOM()
            LIMIT {target_samples}
        """, (datetime.now().isoformat(),))
        
        conn.commit()
        conn.close()
        
        print(f"âœ… åˆ›å»ºå°å‹æ•°æ®é›†æˆåŠŸ: ID={new_dataset_id}, æ ·æœ¬æ•°={target_samples}")
        return new_dataset_id
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ•°æ®é›†å¤±è´¥: {e}")
        return None

def start_optimized_training(dataset_id):
    """å¯åŠ¨å†…å­˜ä¼˜åŒ–çš„è®­ç»ƒä»»åŠ¡"""
    print("ğŸš€ å¯åŠ¨å†…å­˜ä¼˜åŒ–è®­ç»ƒ...")
    
    # è®­ç»ƒé…ç½® - æåº¦ä¿å®ˆçš„å†…å­˜è®¾ç½®
    training_config = {
        "model_name": "Qwen/Qwen2.5-0.5B",  # ä½¿ç”¨æœ€å°çš„æ¨¡å‹
        "dataset_id": dataset_id,
        "epochs": 2,  # å‡å°‘åˆ°2ä¸ªepoch
        "batch_size": 8,  # è¿›ä¸€æ­¥å‡å°batch size
        "learning_rate": 2e-4,
        "max_length": 256,  # å‡å°‘åºåˆ—é•¿åº¦
        "gradient_accumulation_steps": 4,  # ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
        "dataloader_num_workers": 0,  # ä¸ä½¿ç”¨å¤šè¿›ç¨‹
        "fp16": True,  # ä½¿ç”¨åŠç²¾åº¦
        "gradient_checkpointing": True,  # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
        "save_steps": 500,
        "eval_steps": 500,
        "logging_steps": 50,
        "warmup_steps": 100
    }
    
    try:
        conn = sqlite3.connect('mvp/data/bank_code.db')
        cursor = conn.cursor()
        
        # åˆ›å»ºè®­ç»ƒä»»åŠ¡
        cursor.execute("""
            INSERT INTO training_jobs (
                status, model_name, dataset_id, epochs, batch_size, learning_rate,
                total_steps, created_at, started_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            'running',
            training_config['model_name'],
            dataset_id,
            training_config['epochs'],
            training_config['batch_size'],
            training_config['learning_rate'],
            0,  # total_steps will be calculated during training
            datetime.now().isoformat(),
            datetime.now().isoformat()
        ))
        
        job_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        print(f"âœ… è®­ç»ƒä»»åŠ¡åˆ›å»ºæˆåŠŸ: ID={job_id}")
        print("ğŸ“‹ è®­ç»ƒé…ç½®:")
        for key, value in training_config.items():
            print(f"   {key}: {value}")
        
        # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
        cmd = [
            sys.executable, '-c', f"""
import os
import sys
sys.path.append('mvp')

# è®¾ç½®å†…å­˜ä¼˜åŒ–ç¯å¢ƒ
os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.5'
os.environ['PYTORCH_MPS_LOW_WATERMARK_RATIO'] = '0.3'
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
os.environ['OMP_NUM_THREADS'] = '2'

from app.services.model_trainer import ModelTrainer

trainer = ModelTrainer()
trainer.train_model({job_id})
"""
        ]
        
        # åœ¨åå°å¯åŠ¨è®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            cwd='.',
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            env=os.environ.copy()
        )
        
        print(f"ğŸ¯ è®­ç»ƒè¿›ç¨‹å·²å¯åŠ¨: PID={process.pid}")
        return job_id, process.pid
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨è®­ç»ƒå¤±è´¥: {e}")
        return None, None

def monitor_training(job_id):
    """ç›‘æ§è®­ç»ƒè¿›åº¦"""
    print(f"ğŸ“Š å¼€å§‹ç›‘æ§è®­ç»ƒä»»åŠ¡ {job_id}...")
    
    for i in range(10):  # ç›‘æ§10æ¬¡ï¼Œæ¯æ¬¡é—´éš”30ç§’
        try:
            conn = sqlite3.connect('mvp/data/bank_code.db')
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT status, current_step, total_steps, progress_percentage, train_loss
                FROM training_jobs WHERE id = ?
            """, (job_id,))
            
            result = cursor.fetchone()
            conn.close()
            
            if result:
                status, current_step, total_steps, progress, train_loss = result
                print(f"â° [{datetime.now().strftime('%H:%M:%S')}] çŠ¶æ€: {status}")
                if current_step and total_steps:
                    print(f"   è¿›åº¦: {current_step}/{total_steps} ({progress:.2f}%)")
                if train_loss:
                    print(f"   æŸå¤±: {train_loss:.4f}")
                
                if status in ['completed', 'failed']:
                    print(f"ğŸ è®­ç»ƒç»“æŸ: {status}")
                    break
            else:
                print("âŒ æ— æ³•è·å–è®­ç»ƒçŠ¶æ€")
                
        except Exception as e:
            print(f"âš ï¸ ç›‘æ§å‡ºé”™: {e}")
        
        time.sleep(30)

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¦ é“¶è¡Œä»£ç æ£€ç´¢ç³»ç»Ÿ - å†…å­˜ä¼˜åŒ–è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 60)
    
    # 1. è®¾ç½®å†…å­˜ç¯å¢ƒ
    setup_memory_environment()
    
    # 2. æ¸…ç†å†…å­˜
    clear_memory()
    
    # 3. åˆ›å»ºå°æ•°æ®é›†
    dataset_id = create_small_training_dataset()
    if not dataset_id:
        print("âŒ æ— æ³•åˆ›å»ºæ•°æ®é›†ï¼Œé€€å‡º")
        return
    
    # 4. å¯åŠ¨è®­ç»ƒ
    job_id, pid = start_optimized_training(dataset_id)
    if not job_id:
        print("âŒ æ— æ³•å¯åŠ¨è®­ç»ƒï¼Œé€€å‡º")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å†…å­˜ä¼˜åŒ–è®­ç»ƒå·²å¯åŠ¨!")
    print("=" * 60)
    print(f"ğŸ“‹ è®­ç»ƒä»»åŠ¡ID: {job_id}")
    print(f"ğŸ“Š æ•°æ®é›†ID: {dataset_id} (5ä¸‡æ ·æœ¬)")
    print(f"ğŸ”§ è¿›ç¨‹ID: {pid}")
    print(f"ğŸ’¾ å†…å­˜é™åˆ¶: 50% MPSå†…å­˜")
    print(f"âš™ï¸ é…ç½®: 2 epochs, batch_size=8, åŠç²¾åº¦è®­ç»ƒ")
    
    print("\nğŸ“Š ç›‘æ§å‘½ä»¤:")
    print(f"   python3 mvp/system_monitor.py")
    print(f"   tail -f mvp/logs/error_{datetime.now().strftime('%Y-%m-%d')}.log")
    
    # 5. å¼€å§‹ç›‘æ§
    print("\nğŸ” å¼€å§‹ç›‘æ§è®­ç»ƒè¿›åº¦...")
    monitor_training(job_id)

if __name__ == "__main__":
    main()