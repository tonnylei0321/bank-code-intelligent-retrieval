#!/usr/bin/env python3
"""
è®­ç»ƒä»»åŠ¡ç®¡ç†åŠŸèƒ½æµ‹è¯•

æµ‹è¯•æ–°å¢çš„è®­ç»ƒä»»åŠ¡é˜Ÿåˆ—ç®¡ç†ã€ç›‘æ§å’Œæ¢å¤åŠŸèƒ½ã€‚
"""

import sys
import os
import asyncio
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.training_queue_manager import TrainingQueueManager, TaskPriority
from app.services.training_monitor import TrainingMonitor
from app.services.training_recovery import TrainingRecoveryService, FailureType
from app.models.training_job import TrainingJob


class MockDBSession:
    """æ¨¡æ‹Ÿæ•°æ®åº“ä¼šè¯"""
    def __init__(self):
        self.jobs = {}
        self.next_id = 1
    
    def query(self, model):
        return MockQuery(self.jobs, model)
    
    def add(self, obj):
        if hasattr(obj, 'id') and obj.id is None:
            obj.id = self.next_id
            self.next_id += 1
        self.jobs[obj.id] = obj
    
    def commit(self):
        pass
    
    def rollback(self):
        pass
    
    @property
    def is_active(self):
        return True


class MockQuery:
    """æ¨¡æ‹ŸæŸ¥è¯¢å¯¹è±¡"""
    def __init__(self, jobs, model):
        self.jobs = jobs
        self.model = model
        self.filters = []
        self.target_id = None
    
    def filter(self, *args):
        # ç®€åŒ–çš„è¿‡æ»¤å®ç°ï¼Œå‡è®¾æ˜¯æŒ‰IDè¿‡æ»¤
        if hasattr(args[0], 'left') and hasattr(args[0].left, 'name'):
            if args[0].left.name == 'id':
                self.target_id = args[0].right.value
        return self
    
    def first(self):
        if self.target_id and self.target_id in self.jobs:
            return self.jobs[self.target_id]
        elif self.jobs:
            return list(self.jobs.values())[0]
        return None
    
    def all(self):
        return list(self.jobs.values())
    
    def count(self):
        return len(self.jobs)


def create_mock_training_job(job_id: int, status: str = "pending") -> TrainingJob:
    """åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒä»»åŠ¡"""
    job = TrainingJob()
    job.id = job_id
    job.dataset_id = 1
    job.created_by = 1
    job.status = status
    job.model_name = "Qwen/Qwen2.5-0.5B"
    job.epochs = 3
    job.batch_size = 8
    job.learning_rate = 2e-4
    job.lora_r = 16
    job.lora_alpha = 32
    job.lora_dropout = 0.05
    job.created_at = datetime.utcnow()
    job.retry_count = 0
    job.max_retries = 3
    job.priority = "medium"
    return job


def test_queue_manager():
    """æµ‹è¯•é˜Ÿåˆ—ç®¡ç†å™¨åŠŸèƒ½"""
    print("ğŸ”§ æµ‹è¯•è®­ç»ƒé˜Ÿåˆ—ç®¡ç†å™¨...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®åº“å’Œé˜Ÿåˆ—ç®¡ç†å™¨
    mock_db = MockDBSession()
    queue_manager = TrainingQueueManager(mock_db, max_concurrent=2)
    
    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    job1 = create_mock_training_job(1, "pending")
    job2 = create_mock_training_job(2, "pending") 
    job3 = create_mock_training_job(3, "failed")
    
    mock_db.add(job1)
    mock_db.add(job2)
    mock_db.add(job3)
    
    # æµ‹è¯•ä»»åŠ¡å…¥é˜Ÿï¼ˆåªæµ‹è¯•ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼Œé¿å…çŠ¶æ€å†²çªï¼‰
    success1 = queue_manager.enqueue_training_job(1, "high")
    assert success1, "é«˜ä¼˜å…ˆçº§ä»»åŠ¡åº”è¯¥æˆåŠŸå…¥é˜Ÿ"
    
    # æµ‹è¯•é˜Ÿåˆ—çŠ¶æ€
    status = queue_manager.get_queue_status()
    assert status['queue_size'] >= 1, "é˜Ÿåˆ—åº”è¯¥åŒ…å«è‡³å°‘1ä¸ªä»»åŠ¡"
    assert status['max_concurrent'] == 2, "æœ€å¤§å¹¶å‘æ•°åº”è¯¥ä¸º2"
    assert not status['is_processing'], "é˜Ÿåˆ—å¤„ç†åº”è¯¥æœªå¯åŠ¨"
    
    print("âœ… é˜Ÿåˆ—ç®¡ç†å™¨åŠŸèƒ½æ­£å¸¸")


async def test_training_monitor():
    """æµ‹è¯•è®­ç»ƒç›‘æ§åŠŸèƒ½"""
    print("ğŸ“Š æµ‹è¯•è®­ç»ƒç›‘æ§æœåŠ¡...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®åº“å’Œç›‘æ§æœåŠ¡
    mock_db = MockDBSession()
    monitor = TrainingMonitor(mock_db, monitoring_interval=1)
    
    # åˆ›å»ºè¿è¡Œä¸­çš„æµ‹è¯•ä»»åŠ¡
    job = create_mock_training_job(1, "running")
    job.current_epoch = 1
    job.current_step = 100
    job.total_steps = 1000
    job.progress_percentage = 10.0
    job.train_loss = 0.5
    job.started_at = datetime.utcnow()
    
    mock_db.add(job)
    
    # å¯åŠ¨ç›‘æ§
    success = await monitor.start_monitoring()
    assert success, "ç›‘æ§æœåŠ¡åº”è¯¥æˆåŠŸå¯åŠ¨"
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç›‘æ§æ”¶é›†æ•°æ®
    await asyncio.sleep(2)
    
    # è·å–å®æ—¶çŠ¶æ€
    status = await monitor.get_real_time_status(job_id=1)
    assert status['is_monitoring'], "ç›‘æ§åº”è¯¥å¤„äºè¿è¡ŒçŠ¶æ€"
    assert 'system_metrics' in status, "åº”è¯¥åŒ…å«ç³»ç»ŸæŒ‡æ ‡"
    
    # åœæ­¢ç›‘æ§
    success = await monitor.stop_monitoring()
    assert success, "ç›‘æ§æœåŠ¡åº”è¯¥æˆåŠŸåœæ­¢"
    
    print("âœ… è®­ç»ƒç›‘æ§æœåŠ¡åŠŸèƒ½æ­£å¸¸")


def test_recovery_service():
    """æµ‹è¯•è®­ç»ƒæ¢å¤æœåŠ¡"""
    print("ğŸ”„ æµ‹è¯•è®­ç»ƒæ¢å¤æœåŠ¡...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®åº“å’Œæ¢å¤æœåŠ¡
    mock_db = MockDBSession()
    recovery = TrainingRecoveryService(mock_db)
    
    # åˆ›å»ºå¤±è´¥çš„æµ‹è¯•ä»»åŠ¡
    job = create_mock_training_job(1, "failed")
    job.error_message = "CUDA out of memory error occurred during training"
    job.completed_at = datetime.utcnow()
    
    mock_db.add(job)
    
    # æµ‹è¯•å¤±è´¥åˆ†æ
    analysis = recovery.analyze_failure(1)
    assert 'failure_type' in analysis, "åˆ†æç»“æœåº”è¯¥åŒ…å«å¤±è´¥ç±»å‹"
    assert 'recovery_suggestions' in analysis, "åˆ†æç»“æœåº”è¯¥åŒ…å«æ¢å¤å»ºè®®"
    assert analysis['can_retry'], "ä»»åŠ¡åº”è¯¥å¯ä»¥é‡è¯•"
    
    print(f"å¤±è´¥ç±»å‹: {analysis['failure_type']}")
    print(f"æ¢å¤å»ºè®®æ•°é‡: {len(analysis['recovery_suggestions'])}")
    
    # æµ‹è¯•æ¢å¤å°è¯•
    recovery_result = recovery.attempt_recovery(1)
    assert 'success' in recovery_result, "æ¢å¤ç»“æœåº”è¯¥åŒ…å«æˆåŠŸæ ‡å¿—"
    assert 'strategy' in recovery_result, "æ¢å¤ç»“æœåº”è¯¥åŒ…å«ä½¿ç”¨çš„ç­–ç•¥"
    
    print(f"æ¢å¤ç­–ç•¥: {recovery_result['strategy']}")
    print(f"æ¢å¤ç»“æœ: {recovery_result['success']}")
    
    print("âœ… è®­ç»ƒæ¢å¤æœåŠ¡åŠŸèƒ½æ­£å¸¸")


def test_system_integration():
    """æµ‹è¯•ç³»ç»Ÿé›†æˆ"""
    print("ğŸ”— æµ‹è¯•ç³»ç»Ÿé›†æˆ...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®åº“
    mock_db = MockDBSession()
    
    # åˆ›å»ºå„ä¸ªæœåŠ¡
    queue_manager = TrainingQueueManager(mock_db, max_concurrent=1)
    recovery = TrainingRecoveryService(mock_db)
    
    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    job = create_mock_training_job(1, "failed")
    job.error_message = "Training diverged due to high learning rate"
    job.retry_count = 1
    
    mock_db.add(job)
    
    # åˆ†æå¤±è´¥å¹¶å°è¯•æ¢å¤
    analysis = recovery.analyze_failure(1)
    recovery_result = recovery.attempt_recovery(1)
    
    if recovery_result['success']:
        # å¦‚æœæ¢å¤æˆåŠŸï¼Œå°†ä»»åŠ¡é‡æ–°åŠ å…¥é˜Ÿåˆ—
        success = queue_manager.enqueue_training_job(1, "high")
        assert success, "æ¢å¤åçš„ä»»åŠ¡åº”è¯¥èƒ½å¤Ÿé‡æ–°å…¥é˜Ÿ"
        
        # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
        status = queue_manager.get_queue_status()
        assert status['queue_size'] >= 1, "é˜Ÿåˆ—åº”è¯¥åŒ…å«æ¢å¤çš„ä»»åŠ¡"
    
    print("âœ… ç³»ç»Ÿé›†æˆåŠŸèƒ½æ­£å¸¸")


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒä»»åŠ¡ç®¡ç†åŠŸèƒ½æµ‹è¯•...")
    print("=" * 50)
    
    try:
        # åŸºç¡€åŠŸèƒ½æµ‹è¯•
        test_queue_manager()
        await test_training_monitor()
        test_recovery_service()
        test_system_integration()
        
        print("=" * 50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… è®­ç»ƒä»»åŠ¡é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½æ­£å¸¸")
        print("âœ… è®­ç»ƒè¿›åº¦ç›‘æ§åŠŸèƒ½æ­£å¸¸")
        print("âœ… è®­ç»ƒå¤±è´¥æ¢å¤åŠŸèƒ½æ­£å¸¸")
        print("âœ… ç³»ç»Ÿé›†æˆåŠŸèƒ½æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print("=" * 50)
        print(f"âŒ æµ‹è¯•å¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(run_all_tests())
    sys.exit(0 if success else 1)