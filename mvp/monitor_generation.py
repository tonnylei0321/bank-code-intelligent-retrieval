#!/usr/bin/env python3
"""
ç›‘æ§è®­ç»ƒæ•°æ®ç”Ÿæˆè¿›åº¦

å®æ—¶æŸ¥çœ‹ç”Ÿæˆè¿›åº¦ã€ç»Ÿè®¡ä¿¡æ¯å’Œæ€§èƒ½æŒ‡æ ‡
"""

import sys
import os
import time
from datetime import datetime, timedelta
from sqlalchemy import func

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.core.database import get_db
from app.models.qa_pair import QAPair
from app.models.dataset import Dataset
from app.models.bank_code import BankCode


class GenerationMonitor:
    """ç”Ÿæˆè¿›åº¦ç›‘æ§å™¨"""
    
    def __init__(self):
        self.start_time = datetime.now()
        self.last_count = 0
        self.last_check_time = datetime.now()
    
    def get_latest_dataset_id(self):
        """è·å–æœ€æ–°çš„æ•°æ®é›†ID"""
        db = next(get_db())
        try:
            latest_dataset = db.query(Dataset).order_by(Dataset.id.desc()).first()
            return latest_dataset.id if latest_dataset else None
        finally:
            db.close()
    
    def get_generation_stats(self, dataset_id: int = None):
        """è·å–ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        db = next(get_db())
        try:
            # æ€»é“¶è¡Œæ•°
            total_banks = db.query(BankCode).count()
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®é›†ï¼Œä½¿ç”¨æœ€æ–°çš„
            if dataset_id is None:
                dataset_id = self.get_latest_dataset_id()
            
            if dataset_id is None:
                return {
                    "total_banks": total_banks,
                    "generated_samples": 0,
                    "processed_banks": 0,
                    "dataset_name": "æ— æ•°æ®é›†"
                }
            
            # æ•°æ®é›†ä¿¡æ¯
            dataset = db.query(Dataset).filter(Dataset.id == dataset_id).first()
            dataset_name = dataset.name if dataset else f"æ•°æ®é›† {dataset_id}"
            
            # ç”Ÿæˆçš„æ ·æœ¬æ•°
            generated_samples = db.query(QAPair).filter(QAPair.dataset_id == dataset_id).count()
            
            # å¤„ç†çš„é“¶è¡Œæ•°ï¼ˆå»é‡ï¼‰
            processed_banks = db.query(func.count(func.distinct(QAPair.source_record_id))).filter(
                QAPair.dataset_id == dataset_id
            ).scalar()
            
            return {
                "dataset_id": dataset_id,
                "dataset_name": dataset_name,
                "total_banks": total_banks,
                "generated_samples": generated_samples,
                "processed_banks": processed_banks or 0
            }
            
        finally:
            db.close()
    
    def calculate_performance_metrics(self, stats):
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        current_time = datetime.now()
        elapsed_total = (current_time - self.start_time).total_seconds()
        elapsed_interval = (current_time - self.last_check_time).total_seconds()
        
        # æ€»ä½“é€Ÿåº¦
        if elapsed_total > 0:
            samples_per_second = stats["generated_samples"] / elapsed_total
            banks_per_minute = (stats["processed_banks"] * 60) / elapsed_total
        else:
            samples_per_second = 0
            banks_per_minute = 0
        
        # åŒºé—´é€Ÿåº¦
        interval_samples = stats["generated_samples"] - self.last_count
        if elapsed_interval > 0:
            interval_speed = interval_samples / elapsed_interval
        else:
            interval_speed = 0
        
        # é¢„ä¼°å®Œæˆæ—¶é—´
        remaining_banks = stats["total_banks"] - stats["processed_banks"]
        if banks_per_minute > 0:
            eta_minutes = remaining_banks / banks_per_minute
            eta_time = current_time + timedelta(minutes=eta_minutes)
        else:
            eta_minutes = 0
            eta_time = None
        
        # æ›´æ–°çŠ¶æ€
        self.last_count = stats["generated_samples"]
        self.last_check_time = current_time
        
        return {
            "samples_per_second": samples_per_second,
            "banks_per_minute": banks_per_minute,
            "interval_speed": interval_speed,
            "eta_minutes": eta_minutes,
            "eta_time": eta_time,
            "elapsed_minutes": elapsed_total / 60
        }
    
    def print_status(self, stats, metrics):
        """æ‰“å°çŠ¶æ€ä¿¡æ¯"""
        # æ¸…å±
        os.system('clear' if os.name == 'posix' else 'cls')
        
        print("ğŸš€ è®­ç»ƒæ•°æ®ç”Ÿæˆç›‘æ§")
        print("=" * 80)
        print(f"æ•°æ®é›†: {stats['dataset_name']}")
        print(f"å¼€å§‹æ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        # è¿›åº¦ä¿¡æ¯
        progress = (stats["processed_banks"] / stats["total_banks"]) * 100 if stats["total_banks"] > 0 else 0
        
        print("ğŸ“Š è¿›åº¦ç»Ÿè®¡")
        print(f"æ€»é“¶è¡Œæ•°: {stats['total_banks']:,}")
        print(f"å·²å¤„ç†é“¶è¡Œ: {stats['processed_banks']:,}")
        print(f"ç”Ÿæˆæ ·æœ¬æ•°: {stats['generated_samples']:,}")
        print(f"å®Œæˆè¿›åº¦: {progress:.2f}%")
        
        # è¿›åº¦æ¡
        bar_length = 50
        filled_length = int(bar_length * progress / 100)
        bar = "â–ˆ" * filled_length + "â–‘" * (bar_length - filled_length)
        print(f"è¿›åº¦æ¡: [{bar}] {progress:.1f}%")
        
        print("-" * 80)
        
        # æ€§èƒ½æŒ‡æ ‡
        print("âš¡ æ€§èƒ½æŒ‡æ ‡")
        print(f"æ ·æœ¬ç”Ÿæˆé€Ÿåº¦: {metrics['samples_per_second']:.2f} æ ·æœ¬/ç§’")
        print(f"é“¶è¡Œå¤„ç†é€Ÿåº¦: {metrics['banks_per_minute']:.2f} é“¶è¡Œ/åˆ†é’Ÿ")
        print(f"åŒºé—´é€Ÿåº¦: {metrics['interval_speed']:.2f} æ ·æœ¬/ç§’")
        print(f"è¿è¡Œæ—¶é—´: {metrics['elapsed_minutes']:.1f} åˆ†é’Ÿ")
        
        if metrics['eta_time']:
            print(f"é¢„è®¡å®Œæˆæ—¶é—´: {metrics['eta_time'].strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"å‰©ä½™æ—¶é—´: {metrics['eta_minutes']:.1f} åˆ†é’Ÿ")
        
        print("-" * 80)
        
        # è´¨é‡æŒ‡æ ‡
        if stats["processed_banks"] > 0:
            avg_samples_per_bank = stats["generated_samples"] / stats["processed_banks"]
            print("ğŸ“ˆ è´¨é‡æŒ‡æ ‡")
            print(f"å¹³å‡æ¯é“¶è¡Œæ ·æœ¬æ•°: {avg_samples_per_bank:.2f}")
            
            if avg_samples_per_bank < 5:
                print("âš ï¸  è­¦å‘Š: å¹³å‡æ ·æœ¬æ•°åä½ï¼Œå¯èƒ½å­˜åœ¨ç”Ÿæˆé—®é¢˜")
            elif avg_samples_per_bank > 8:
                print("âš ï¸  è­¦å‘Š: å¹³å‡æ ·æœ¬æ•°åé«˜ï¼Œå¯èƒ½å­˜åœ¨é‡å¤ç”Ÿæˆ")
            else:
                print("âœ… æ ·æœ¬ç”Ÿæˆè´¨é‡æ­£å¸¸")
        
        print("=" * 80)
        print("æŒ‰ Ctrl+C é€€å‡ºç›‘æ§")
    
    def run_monitor(self, dataset_id: int = None, interval: int = 5):
        """è¿è¡Œç›‘æ§"""
        print("ğŸ” å¯åŠ¨ç”Ÿæˆè¿›åº¦ç›‘æ§...")
        
        try:
            while True:
                stats = self.get_generation_stats(dataset_id)
                metrics = self.calculate_performance_metrics(stats)
                self.print_status(stats, metrics)
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if stats["processed_banks"] >= stats["total_banks"] and stats["total_banks"] > 0:
                    print("\nğŸ‰ ç”Ÿæˆå®Œæˆï¼")
                    break
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")


def main():
    """ä¸»å‡½æ•°"""
    monitor = GenerationMonitor()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    dataset_id = None
    interval = 5
    
    if len(sys.argv) > 1:
        try:
            dataset_id = int(sys.argv[1])
            print(f"ç›‘æ§æ•°æ®é›† ID: {dataset_id}")
        except ValueError:
            print("æ— æ•ˆçš„æ•°æ®é›†IDï¼Œå°†ç›‘æ§æœ€æ–°æ•°æ®é›†")
    
    if len(sys.argv) > 2:
        try:
            interval = int(sys.argv[2])
            print(f"åˆ·æ–°é—´éš”: {interval} ç§’")
        except ValueError:
            print("æ— æ•ˆçš„åˆ·æ–°é—´éš”ï¼Œä½¿ç”¨é»˜è®¤å€¼ 5 ç§’")
    
    monitor.run_monitor(dataset_id, interval)


if __name__ == "__main__":
    main()